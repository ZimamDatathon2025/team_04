{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Core Libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Visualization\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "\n",
    "sns.set_style(\"whitegrid\")\n",
    "np.random.seed(42) "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Conda env name: dubai-datathon-team4\n",
    "python version 3.9 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape: (15045, 57)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>patient_id</th>\n",
       "      <th>hadm_id</th>\n",
       "      <th>icustay_id</th>\n",
       "      <th>age</th>\n",
       "      <th>gender</th>\n",
       "      <th>race</th>\n",
       "      <th>weight</th>\n",
       "      <th>insurance</th>\n",
       "      <th>language</th>\n",
       "      <th>admission_type</th>\n",
       "      <th>...</th>\n",
       "      <th>on_diuretics</th>\n",
       "      <th>diuretic_type</th>\n",
       "      <th>ldh</th>\n",
       "      <th>bilirubin_total</th>\n",
       "      <th>bilirubin_direct</th>\n",
       "      <th>possible_hemolysis</th>\n",
       "      <th>in_hospital_mortality</th>\n",
       "      <th>dod</th>\n",
       "      <th>los_hospital_days</th>\n",
       "      <th>los_icu_days</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10002114</td>\n",
       "      <td>27793700</td>\n",
       "      <td>34672098</td>\n",
       "      <td>56</td>\n",
       "      <td>M</td>\n",
       "      <td>UNKNOWN</td>\n",
       "      <td>64.0</td>\n",
       "      <td>Medicaid</td>\n",
       "      <td>English</td>\n",
       "      <td>OBSERVATION ADMIT</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>bumetanide</td>\n",
       "      <td>343.0</td>\n",
       "      <td>1.1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2162-12-11</td>\n",
       "      <td>14.708333</td>\n",
       "      <td>2.916667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10002155</td>\n",
       "      <td>28994087</td>\n",
       "      <td>31090461</td>\n",
       "      <td>80</td>\n",
       "      <td>F</td>\n",
       "      <td>WHITE</td>\n",
       "      <td>47.9</td>\n",
       "      <td>Medicare</td>\n",
       "      <td>English</td>\n",
       "      <td>EW EMER.</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>bumetanide</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2131-03-10</td>\n",
       "      <td>5.875000</td>\n",
       "      <td>3.916667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10002428</td>\n",
       "      <td>23473524</td>\n",
       "      <td>35479615</td>\n",
       "      <td>80</td>\n",
       "      <td>F</td>\n",
       "      <td>WHITE</td>\n",
       "      <td>49.3</td>\n",
       "      <td>Medicare</td>\n",
       "      <td>English</td>\n",
       "      <td>EW EMER.</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>furosemide</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>11.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10003400</td>\n",
       "      <td>20214994</td>\n",
       "      <td>32128372</td>\n",
       "      <td>72</td>\n",
       "      <td>F</td>\n",
       "      <td>BLACK/AFRICAN AMERICAN</td>\n",
       "      <td>94.1</td>\n",
       "      <td>Medicare</td>\n",
       "      <td>English</td>\n",
       "      <td>URGENT</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>furosemide</td>\n",
       "      <td>536.0</td>\n",
       "      <td>6.5</td>\n",
       "      <td>4.3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2137-09-02</td>\n",
       "      <td>23.208333</td>\n",
       "      <td>12.916667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10004401</td>\n",
       "      <td>29988601</td>\n",
       "      <td>32773003</td>\n",
       "      <td>82</td>\n",
       "      <td>M</td>\n",
       "      <td>WHITE</td>\n",
       "      <td>75.8</td>\n",
       "      <td>Medicare</td>\n",
       "      <td>English</td>\n",
       "      <td>EW EMER.</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>furosemide</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2144-06-18</td>\n",
       "      <td>14.166667</td>\n",
       "      <td>10.625000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 57 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   patient_id   hadm_id  icustay_id  age gender                    race  \\\n",
       "0    10002114  27793700    34672098   56      M                 UNKNOWN   \n",
       "1    10002155  28994087    31090461   80      F                   WHITE   \n",
       "2    10002428  23473524    35479615   80      F                   WHITE   \n",
       "3    10003400  20214994    32128372   72      F  BLACK/AFRICAN AMERICAN   \n",
       "4    10004401  29988601    32773003   82      M                   WHITE   \n",
       "\n",
       "   weight insurance language     admission_type  ... on_diuretics  \\\n",
       "0    64.0  Medicaid  English  OBSERVATION ADMIT  ...            1   \n",
       "1    47.9  Medicare  English           EW EMER.  ...            1   \n",
       "2    49.3  Medicare  English           EW EMER.  ...            1   \n",
       "3    94.1  Medicare  English             URGENT  ...            1   \n",
       "4    75.8  Medicare  English           EW EMER.  ...            1   \n",
       "\n",
       "   diuretic_type    ldh  bilirubin_total bilirubin_direct possible_hemolysis  \\\n",
       "0     bumetanide  343.0              1.1              NaN                  1   \n",
       "1     bumetanide    NaN              NaN              NaN                  0   \n",
       "2     furosemide    NaN              NaN              NaN                  0   \n",
       "3     furosemide  536.0              6.5              4.3                  1   \n",
       "4     furosemide    NaN              NaN              NaN                  0   \n",
       "\n",
       "   in_hospital_mortality         dod  los_hospital_days  los_icu_days  \n",
       "0                      0  2162-12-11          14.708333      2.916667  \n",
       "1                      0  2131-03-10           5.875000      3.916667  \n",
       "2                      0         NaN          11.000000     11.000000  \n",
       "3                      0  2137-09-02          23.208333     12.916667  \n",
       "4                      0  2144-06-18          14.166667     10.625000  \n",
       "\n",
       "[5 rows x 57 columns]"
      ]
     },
     "execution_count": 205,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load data\n",
    "data = pd.read_csv(\"/Users/mac/Desktop/Dubai-Datathon-2025/team4/data/blood_transfusion.csv\") \n",
    "\n",
    "# Preview\n",
    "print(\"Shape:\", data.shape)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 15,045 patient records\n",
      "Columns: ['patient_id', 'hadm_id', 'icustay_id', 'age', 'gender', 'race', 'weight', 'insurance', 'language', 'admission_type', 'primary_icd_code', 'icd_version', 'primary_icd_long_title', 'ongoing_bleeding', 'icu_admission_time', 'first_transfusion_time', 'time_to_first_transfusion_hours', 'early_transfusion', 'number_of_transfusions', 'units_first_transfusion', 'total_units_transfused', 'transfusion_during_vasopressor', 'sofa_score', 'heart_disease', 'kidney_disease', 'history_of_bleeding', 'sepsis', 'baseline_hemoglobin', 'pre_transfusion_hemoglobin', 'post_transfusion_hemoglobin', 'hemoglobin_ordered', 'how_many_times_hemoglobin_ordered', 'baseline_wbc', 'baseline_platelets', 'baseline_hematocrit', 'baseline_creatinine', 'baseline_spo2', 'baseline_sao2', 'spo2_measurement_count', 'baseline_bp_systolic', 'baseline_bp_diastolic', 'on_vasopressors', 'vasopressor_type', 'vasopressor_start_time', 'vasopressor_stop_time', 'vasopressor_duration_hours', 'successful_weaning', 'on_diuretics', 'diuretic_type', 'ldh', 'bilirubin_total', 'bilirubin_direct', 'possible_hemolysis', 'in_hospital_mortality', 'dod', 'los_hospital_days', 'los_icu_days']\n",
      "\n",
      "Dataframe shape: (15045, 57)\n",
      "\n",
      "Data types:\n",
      "patient_id                             int64\n",
      "hadm_id                                int64\n",
      "icustay_id                             int64\n",
      "age                                    int64\n",
      "gender                                object\n",
      "race                                  object\n",
      "weight                               float64\n",
      "insurance                             object\n",
      "language                              object\n",
      "admission_type                        object\n",
      "primary_icd_code                      object\n",
      "icd_version                          float64\n",
      "primary_icd_long_title                object\n",
      "ongoing_bleeding                       int64\n",
      "icu_admission_time                    object\n",
      "first_transfusion_time                object\n",
      "time_to_first_transfusion_hours      float64\n",
      "early_transfusion                      int64\n",
      "number_of_transfusions                 int64\n",
      "units_first_transfusion              float64\n",
      "total_units_transfused               float64\n",
      "transfusion_during_vasopressor         int64\n",
      "sofa_score                             int64\n",
      "heart_disease                          int64\n",
      "kidney_disease                         int64\n",
      "history_of_bleeding                    int64\n",
      "sepsis                                 int64\n",
      "baseline_hemoglobin                  float64\n",
      "pre_transfusion_hemoglobin           float64\n",
      "post_transfusion_hemoglobin          float64\n",
      "hemoglobin_ordered                     int64\n",
      "how_many_times_hemoglobin_ordered      int64\n",
      "baseline_wbc                         float64\n",
      "baseline_platelets                   float64\n",
      "baseline_hematocrit                  float64\n",
      "baseline_creatinine                  float64\n",
      "baseline_spo2                        float64\n",
      "baseline_sao2                        float64\n",
      "spo2_measurement_count                 int64\n",
      "baseline_bp_systolic                 float64\n",
      "baseline_bp_diastolic                float64\n",
      "on_vasopressors                        int64\n",
      "vasopressor_type                      object\n",
      "vasopressor_start_time                object\n",
      "vasopressor_stop_time                 object\n",
      "vasopressor_duration_hours           float64\n",
      "successful_weaning                   float64\n",
      "on_diuretics                           int64\n",
      "diuretic_type                         object\n",
      "ldh                                  float64\n",
      "bilirubin_total                      float64\n",
      "bilirubin_direct                     float64\n",
      "possible_hemolysis                     int64\n",
      "in_hospital_mortality                  int64\n",
      "dod                                   object\n",
      "los_hospital_days                    float64\n",
      "los_icu_days                         float64\n",
      "dtype: object\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 15045 entries, 0 to 15044\n",
      "Data columns (total 57 columns):\n",
      " #   Column                             Non-Null Count  Dtype  \n",
      "---  ------                             --------------  -----  \n",
      " 0   patient_id                         15045 non-null  int64  \n",
      " 1   hadm_id                            15045 non-null  int64  \n",
      " 2   icustay_id                         15045 non-null  int64  \n",
      " 3   age                                15045 non-null  int64  \n",
      " 4   gender                             15045 non-null  object \n",
      " 5   race                               15045 non-null  object \n",
      " 6   weight                             12408 non-null  float64\n",
      " 7   insurance                          14828 non-null  object \n",
      " 8   language                           14942 non-null  object \n",
      " 9   admission_type                     15045 non-null  object \n",
      " 10  primary_icd_code                   15041 non-null  object \n",
      " 11  icd_version                        15041 non-null  float64\n",
      " 12  primary_icd_long_title             15041 non-null  object \n",
      " 13  ongoing_bleeding                   15045 non-null  int64  \n",
      " 14  icu_admission_time                 15045 non-null  object \n",
      " 15  first_transfusion_time             15045 non-null  object \n",
      " 16  time_to_first_transfusion_hours    15045 non-null  float64\n",
      " 17  early_transfusion                  15045 non-null  int64  \n",
      " 18  number_of_transfusions             15045 non-null  int64  \n",
      " 19  units_first_transfusion            15045 non-null  float64\n",
      " 20  total_units_transfused             15045 non-null  float64\n",
      " 21  transfusion_during_vasopressor     15045 non-null  int64  \n",
      " 22  sofa_score                         15045 non-null  int64  \n",
      " 23  heart_disease                      15045 non-null  int64  \n",
      " 24  kidney_disease                     15045 non-null  int64  \n",
      " 25  history_of_bleeding                15045 non-null  int64  \n",
      " 26  sepsis                             15045 non-null  int64  \n",
      " 27  baseline_hemoglobin                13398 non-null  float64\n",
      " 28  pre_transfusion_hemoglobin         12427 non-null  float64\n",
      " 29  post_transfusion_hemoglobin        14616 non-null  float64\n",
      " 30  hemoglobin_ordered                 15045 non-null  int64  \n",
      " 31  how_many_times_hemoglobin_ordered  15045 non-null  int64  \n",
      " 32  baseline_wbc                       13109 non-null  float64\n",
      " 33  baseline_platelets                 13150 non-null  float64\n",
      " 34  baseline_hematocrit                13605 non-null  float64\n",
      " 35  baseline_creatinine                14959 non-null  float64\n",
      " 36  baseline_spo2                      14588 non-null  float64\n",
      " 37  baseline_sao2                      4141 non-null   float64\n",
      " 38  spo2_measurement_count             15045 non-null  int64  \n",
      " 39  baseline_bp_systolic               14583 non-null  float64\n",
      " 40  baseline_bp_diastolic              14583 non-null  float64\n",
      " 41  on_vasopressors                    15045 non-null  int64  \n",
      " 42  vasopressor_type                   15045 non-null  object \n",
      " 43  vasopressor_start_time             8596 non-null   object \n",
      " 44  vasopressor_stop_time              8596 non-null   object \n",
      " 45  vasopressor_duration_hours         8596 non-null   float64\n",
      " 46  successful_weaning                 8596 non-null   float64\n",
      " 47  on_diuretics                       15045 non-null  int64  \n",
      " 48  diuretic_type                      13561 non-null  object \n",
      " 49  ldh                                6615 non-null   float64\n",
      " 50  bilirubin_total                    8871 non-null   float64\n",
      " 51  bilirubin_direct                   1411 non-null   float64\n",
      " 52  possible_hemolysis                 15045 non-null  int64  \n",
      " 53  in_hospital_mortality              15045 non-null  int64  \n",
      " 54  dod                                7086 non-null   object \n",
      " 55  los_hospital_days                  15045 non-null  float64\n",
      " 56  los_icu_days                       15042 non-null  float64\n",
      "dtypes: float64(23), int64(20), object(14)\n",
      "memory usage: 6.5+ MB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(f\"Loaded {len(data):,} patient records\")\n",
    "print(f\"Columns: {data.columns.tolist()}\")\n",
    "print(f\"\\nDataframe shape: {data.shape}\")\n",
    "print(f\"\\nData types:\\n{data.dtypes}\")\n",
    "print(data.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                   n_missing  missing_%\n",
      "bilirubin_direct                       13634      90.62\n",
      "baseline_sao2                          10904      72.48\n",
      "ldh                                     8430      56.03\n",
      "dod                                     7959      52.90\n",
      "successful_weaning                      6449      42.86\n",
      "vasopressor_duration_hours              6449      42.86\n",
      "vasopressor_start_time                  6449      42.86\n",
      "vasopressor_stop_time                   6449      42.86\n",
      "bilirubin_total                         6174      41.04\n",
      "weight                                  2637      17.53\n",
      "pre_transfusion_hemoglobin              2618      17.40\n",
      "baseline_wbc                            1936      12.87\n",
      "baseline_platelets                      1895      12.60\n",
      "baseline_hemoglobin                     1647      10.95\n",
      "diuretic_type                           1484       9.86\n",
      "baseline_hematocrit                     1440       9.57\n",
      "baseline_bp_diastolic                    462       3.07\n",
      "baseline_bp_systolic                     462       3.07\n",
      "baseline_spo2                            457       3.04\n",
      "post_transfusion_hemoglobin              429       2.85\n",
      "insurance                                217       1.44\n",
      "language                                 103       0.68\n",
      "baseline_creatinine                       86       0.57\n",
      "icd_version                                4       0.03\n",
      "primary_icd_long_title                     4       0.03\n",
      "primary_icd_code                           4       0.03\n",
      "los_icu_days                               3       0.02\n",
      "sepsis                                     0       0.00\n",
      "hadm_id                                    0       0.00\n",
      "los_hospital_days                          0       0.00\n",
      "icustay_id                                 0       0.00\n",
      "in_hospital_mortality                      0       0.00\n",
      "possible_hemolysis                         0       0.00\n",
      "age                                        0       0.00\n",
      "gender                                     0       0.00\n",
      "race                                       0       0.00\n",
      "admission_type                             0       0.00\n",
      "on_diuretics                               0       0.00\n",
      "ongoing_bleeding                           0       0.00\n",
      "icu_admission_time                         0       0.00\n",
      "first_transfusion_time                     0       0.00\n",
      "time_to_first_transfusion_hours            0       0.00\n",
      "vasopressor_type                           0       0.00\n",
      "on_vasopressors                            0       0.00\n",
      "early_transfusion                          0       0.00\n",
      "number_of_transfusions                     0       0.00\n",
      "spo2_measurement_count                     0       0.00\n",
      "units_first_transfusion                    0       0.00\n",
      "total_units_transfused                     0       0.00\n",
      "transfusion_during_vasopressor             0       0.00\n",
      "sofa_score                                 0       0.00\n",
      "heart_disease                              0       0.00\n",
      "kidney_disease                             0       0.00\n",
      "how_many_times_hemoglobin_ordered          0       0.00\n",
      "hemoglobin_ordered                         0       0.00\n",
      "history_of_bleeding                        0       0.00\n",
      "patient_id                                 0       0.00\n",
      "Total columns: 57, total rows: 15045\n"
     ]
    }
   ],
   "source": [
    "na_counts = data.isna().sum()\n",
    "\n",
    "# Percentage of missing values per column\n",
    "# Series[float] — same index, values = percentage of NaNs (0–100)\n",
    "na_percent = (data.isna().mean() * 100).round(2)\n",
    "\n",
    "# Combine both into a single DataFrame for readability\n",
    "# DataFrame with two columns: 'n_missing' and 'missing_%'\n",
    "missing_summary = pd.DataFrame({\n",
    "    \"n_missing\": na_counts,\n",
    "    \"missing_%\": na_percent\n",
    "}).sort_values(by=\"missing_%\", ascending=False)\n",
    "\n",
    "print (missing_summary)\n",
    "\n",
    "# Display top rows — shows columns with the most missingness first\n",
    "print(f\"Total columns: {data.shape[1]}, total rows: {data.shape[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dropped columns: ['bilirubin_direct', 'bilirubin_total', 'weight', 'ldh', 'dod']\n",
      "Current number of patient records: 15,045\n"
     ]
    }
   ],
   "source": [
    "# Handling missing values\n",
    "\n",
    "# -------------------------------\n",
    "# 1) Drop specified columns\n",
    "# -------------------------------\n",
    "cols_to_drop = [\n",
    "    \"bilirubin_direct\",  # DOES NOT MATTER \n",
    "    \"bilirubin_total\",   # DOES NOT MATTER \n",
    "    \"weight\",            # DOES NOT MATTER \n",
    "    \"ldh\",               # MATTERS BUT not that relevant\n",
    "    \"dod\",\n",
    "]\n",
    "\n",
    "# Keep only columns that actually exist to avoid KeyError\n",
    "existing_to_drop = [c for c in cols_to_drop if c in data.columns]\n",
    "\n",
    "# drop\n",
    "data_irr_dropped = data.drop(columns=existing_to_drop)\n",
    "\n",
    "print(f\"Dropped columns: {existing_to_drop}\")\n",
    "print(f\"Current number of patient records: {len(data_irr_dropped):,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rows before: 15045\n",
      "Rows with missing values in ['pre_transfusion_hemoglobin', 'baseline_wbc', 'baseline_platelets', 'baseline_hemoglobin', 'diuretic_type', 'baseline_hematocrit', 'baseline_bp_diastolic', 'baseline_bp_systolic', 'baseline_spo2', 'post_transfusion_hemoglobin', 'insurance', 'language', 'baseline_creatinine', 'icd_version', 'primary_icd_long_title', 'primary_icd_code', 'los_icu_days']: 5352\n",
      "Rows after: 9693 (dropped 5352)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# -----------------------------------------------\n",
    "# Drop rows where any of these key columns are missing\n",
    "# -----------------------------------------------\n",
    "\n",
    "\n",
    "\n",
    "cols_to_check = [\n",
    "    \"pre_transfusion_hemoglobin\",   # MATTER -> 17.40\n",
    "    \"baseline_wbc\",                 # MATTER -> 12.87\n",
    "    \"baseline_platelets\",           # MATTER -> 12.60\n",
    "    \"baseline_hemoglobin\",          # MATTER -> 10.95\n",
    "    \"diuretic_type\",                # NOT THAT IMPORTANT - only for patients 65% & already it s only 9.86% \n",
    "    \"baseline_hematocrit\",          # MATTER -> 9.57\n",
    "    \"baseline_bp_diastolic\",\n",
    "    \"baseline_bp_systolic\",\n",
    "    \"baseline_spo2\",\n",
    "    \"post_transfusion_hemoglobin\",\n",
    "    \"insurance\",\n",
    "    \"language\",\n",
    "    \"baseline_creatinine\",\n",
    "    \"icd_version\",\n",
    "    \"primary_icd_long_title\",\n",
    "    \"primary_icd_code\",\n",
    "    \"los_icu_days\"\n",
    "]\n",
    "\n",
    "\n",
    "# Keep only columns that actually exist in the dataframe\n",
    "existing_cols = [c for c in cols_to_check if c in data_irr_dropped.columns]\n",
    "\n",
    "# Display how many rows will be dropped\n",
    "n_before = len(data_irr_dropped)\n",
    "n_missing_rows = data_irr_dropped[existing_cols].isna().any(axis=1).sum()\n",
    "\n",
    "print(f\"Rows before: {n_before}\")\n",
    "print(f\"Rows with missing values in {existing_cols}: {n_missing_rows}\")\n",
    "\n",
    "# Drop rows with any NaN in these columns\n",
    "data_irr_dropped_2 = data_irr_dropped.dropna(subset=existing_cols).reset_index(drop=True)\n",
    "\n",
    "print(f\"Rows after: {len(data_irr_dropped_2)} (dropped {n_missing_rows})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== SaO2 Missingness by Race ===\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>total_rows</th>\n",
       "      <th>n_missing_sao2</th>\n",
       "      <th>missing_pct_sao2</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>race</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>ASIAN - KOREAN</th>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>100.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>WHITE - BRAZILIAN</th>\n",
       "      <td>14</td>\n",
       "      <td>12</td>\n",
       "      <td>85.71</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BLACK/CARIBBEAN ISLAND</th>\n",
       "      <td>63</td>\n",
       "      <td>52</td>\n",
       "      <td>82.54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AMERICAN INDIAN/ALASKA NATIVE</th>\n",
       "      <td>25</td>\n",
       "      <td>20</td>\n",
       "      <td>80.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SOUTH AMERICAN</th>\n",
       "      <td>9</td>\n",
       "      <td>7</td>\n",
       "      <td>77.78</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HISPANIC/LATINO - CENTRAL AMERICAN</th>\n",
       "      <td>9</td>\n",
       "      <td>7</td>\n",
       "      <td>77.78</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HISPANIC/LATINO - MEXICAN</th>\n",
       "      <td>9</td>\n",
       "      <td>7</td>\n",
       "      <td>77.78</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HISPANIC/LATINO - GUATEMALAN</th>\n",
       "      <td>19</td>\n",
       "      <td>14</td>\n",
       "      <td>73.68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BLACK/AFRICAN</th>\n",
       "      <td>34</td>\n",
       "      <td>25</td>\n",
       "      <td>73.53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MULTIPLE RACE/ETHNICITY</th>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>71.43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BLACK/CAPE VERDEAN</th>\n",
       "      <td>52</td>\n",
       "      <td>37</td>\n",
       "      <td>71.15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HISPANIC/LATINO - CUBAN</th>\n",
       "      <td>13</td>\n",
       "      <td>9</td>\n",
       "      <td>69.23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>OTHER</th>\n",
       "      <td>326</td>\n",
       "      <td>220</td>\n",
       "      <td>67.48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BLACK/AFRICAN AMERICAN</th>\n",
       "      <td>688</td>\n",
       "      <td>464</td>\n",
       "      <td>67.44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HISPANIC/LATINO - COLUMBIAN</th>\n",
       "      <td>9</td>\n",
       "      <td>6</td>\n",
       "      <td>66.67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ASIAN</th>\n",
       "      <td>118</td>\n",
       "      <td>78</td>\n",
       "      <td>66.10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>UNKNOWN</th>\n",
       "      <td>1110</td>\n",
       "      <td>726</td>\n",
       "      <td>65.41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ASIAN - CHINESE</th>\n",
       "      <td>104</td>\n",
       "      <td>67</td>\n",
       "      <td>64.42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>WHITE - RUSSIAN</th>\n",
       "      <td>53</td>\n",
       "      <td>34</td>\n",
       "      <td>64.15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HISPANIC/LATINO - SALVADORAN</th>\n",
       "      <td>11</td>\n",
       "      <td>7</td>\n",
       "      <td>63.64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HISPANIC/LATINO - HONDURAN</th>\n",
       "      <td>11</td>\n",
       "      <td>7</td>\n",
       "      <td>63.64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>WHITE</th>\n",
       "      <td>6147</td>\n",
       "      <td>3911</td>\n",
       "      <td>63.62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ASIAN - SOUTH EAST ASIAN</th>\n",
       "      <td>40</td>\n",
       "      <td>25</td>\n",
       "      <td>62.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>WHITE - OTHER EUROPEAN</th>\n",
       "      <td>202</td>\n",
       "      <td>126</td>\n",
       "      <td>62.38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HISPANIC/LATINO - PUERTO RICAN</th>\n",
       "      <td>127</td>\n",
       "      <td>77</td>\n",
       "      <td>60.63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>WHITE - EASTERN EUROPEAN</th>\n",
       "      <td>20</td>\n",
       "      <td>12</td>\n",
       "      <td>60.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HISPANIC OR LATINO</th>\n",
       "      <td>76</td>\n",
       "      <td>45</td>\n",
       "      <td>59.21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>UNABLE TO OBTAIN</th>\n",
       "      <td>156</td>\n",
       "      <td>89</td>\n",
       "      <td>57.05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HISPANIC/LATINO - DOMINICAN</th>\n",
       "      <td>76</td>\n",
       "      <td>43</td>\n",
       "      <td>56.58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ASIAN - ASIAN INDIAN</th>\n",
       "      <td>25</td>\n",
       "      <td>14</td>\n",
       "      <td>56.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PATIENT DECLINED TO ANSWER</th>\n",
       "      <td>75</td>\n",
       "      <td>40</td>\n",
       "      <td>53.33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PORTUGUESE</th>\n",
       "      <td>48</td>\n",
       "      <td>25</td>\n",
       "      <td>52.08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NATIVE HAWAIIAN OR OTHER PACIFIC ISLANDER</th>\n",
       "      <td>9</td>\n",
       "      <td>4</td>\n",
       "      <td>44.44</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           total_rows  n_missing_sao2  \\\n",
       "race                                                                    \n",
       "ASIAN - KOREAN                                      8               8   \n",
       "WHITE - BRAZILIAN                                  14              12   \n",
       "BLACK/CARIBBEAN ISLAND                             63              52   \n",
       "AMERICAN INDIAN/ALASKA NATIVE                      25              20   \n",
       "SOUTH AMERICAN                                      9               7   \n",
       "HISPANIC/LATINO - CENTRAL AMERICAN                  9               7   \n",
       "HISPANIC/LATINO - MEXICAN                           9               7   \n",
       "HISPANIC/LATINO - GUATEMALAN                       19              14   \n",
       "BLACK/AFRICAN                                      34              25   \n",
       "MULTIPLE RACE/ETHNICITY                             7               5   \n",
       "BLACK/CAPE VERDEAN                                 52              37   \n",
       "HISPANIC/LATINO - CUBAN                            13               9   \n",
       "OTHER                                             326             220   \n",
       "BLACK/AFRICAN AMERICAN                            688             464   \n",
       "HISPANIC/LATINO - COLUMBIAN                         9               6   \n",
       "ASIAN                                             118              78   \n",
       "UNKNOWN                                          1110             726   \n",
       "ASIAN - CHINESE                                   104              67   \n",
       "WHITE - RUSSIAN                                    53              34   \n",
       "HISPANIC/LATINO - SALVADORAN                       11               7   \n",
       "HISPANIC/LATINO - HONDURAN                         11               7   \n",
       "WHITE                                            6147            3911   \n",
       "ASIAN - SOUTH EAST ASIAN                           40              25   \n",
       "WHITE - OTHER EUROPEAN                            202             126   \n",
       "HISPANIC/LATINO - PUERTO RICAN                    127              77   \n",
       "WHITE - EASTERN EUROPEAN                           20              12   \n",
       "HISPANIC OR LATINO                                 76              45   \n",
       "UNABLE TO OBTAIN                                  156              89   \n",
       "HISPANIC/LATINO - DOMINICAN                        76              43   \n",
       "ASIAN - ASIAN INDIAN                               25              14   \n",
       "PATIENT DECLINED TO ANSWER                         75              40   \n",
       "PORTUGUESE                                         48              25   \n",
       "NATIVE HAWAIIAN OR OTHER PACIFIC ISLANDER           9               4   \n",
       "\n",
       "                                           missing_pct_sao2  \n",
       "race                                                         \n",
       "ASIAN - KOREAN                                       100.00  \n",
       "WHITE - BRAZILIAN                                     85.71  \n",
       "BLACK/CARIBBEAN ISLAND                                82.54  \n",
       "AMERICAN INDIAN/ALASKA NATIVE                         80.00  \n",
       "SOUTH AMERICAN                                        77.78  \n",
       "HISPANIC/LATINO - CENTRAL AMERICAN                    77.78  \n",
       "HISPANIC/LATINO - MEXICAN                             77.78  \n",
       "HISPANIC/LATINO - GUATEMALAN                          73.68  \n",
       "BLACK/AFRICAN                                         73.53  \n",
       "MULTIPLE RACE/ETHNICITY                               71.43  \n",
       "BLACK/CAPE VERDEAN                                    71.15  \n",
       "HISPANIC/LATINO - CUBAN                               69.23  \n",
       "OTHER                                                 67.48  \n",
       "BLACK/AFRICAN AMERICAN                                67.44  \n",
       "HISPANIC/LATINO - COLUMBIAN                           66.67  \n",
       "ASIAN                                                 66.10  \n",
       "UNKNOWN                                               65.41  \n",
       "ASIAN - CHINESE                                       64.42  \n",
       "WHITE - RUSSIAN                                       64.15  \n",
       "HISPANIC/LATINO - SALVADORAN                          63.64  \n",
       "HISPANIC/LATINO - HONDURAN                            63.64  \n",
       "WHITE                                                 63.62  \n",
       "ASIAN - SOUTH EAST ASIAN                              62.50  \n",
       "WHITE - OTHER EUROPEAN                                62.38  \n",
       "HISPANIC/LATINO - PUERTO RICAN                        60.63  \n",
       "WHITE - EASTERN EUROPEAN                              60.00  \n",
       "HISPANIC OR LATINO                                    59.21  \n",
       "UNABLE TO OBTAIN                                      57.05  \n",
       "HISPANIC/LATINO - DOMINICAN                           56.58  \n",
       "ASIAN - ASIAN INDIAN                                  56.00  \n",
       "PATIENT DECLINED TO ANSWER                            53.33  \n",
       "PORTUGUESE                                            52.08  \n",
       "NATIVE HAWAIIAN OR OTHER PACIFIC ISLANDER             44.44  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Imputed baseline_sao2 using baseline_spo2 for 6223 rows (remaining NaNs: 0).\n"
     ]
    }
   ],
   "source": [
    "# -------------------------------\n",
    "# 2) Baseline SaO2:\n",
    "#    a) Make a table showing SaO2 missingness across race\n",
    "#    b) Impute baseline_sao2 with baseline_spo2 when missing\n",
    "# -------------------------------\n",
    "if \"race\" not in data_irr_dropped_2.columns:\n",
    "    raise KeyError(\"Column 'race' not found. Needed for missingness-by-race table.\")\n",
    "\n",
    "if \"baseline_sao2\" not in data_irr_dropped_2.columns:\n",
    "    raise KeyError(\"Column 'baseline_sao2' not found.\")\n",
    "\n",
    "if \"baseline_spo2\" not in data_irr_dropped_2.columns:\n",
    "    raise KeyError(\"Column 'baseline_spo2' not found to use for imputation of baseline_sao2.\")\n",
    "\n",
    "# Build a concise missingness table for SaO2 by race\n",
    "tmp = (\n",
    "    data_irr_dropped_2.groupby(\"race\")\n",
    "        .agg(\n",
    "            total_rows=(\"baseline_sao2\", \"size\"),\n",
    "            n_missing_sao2=(\"baseline_sao2\", lambda s: s.isna().sum())\n",
    "        )\n",
    "        .assign(missing_pct_sao2=lambda df: (df[\"n_missing_sao2\"] / df[\"total_rows\"] * 100).round(2))\n",
    "        .sort_values(\"missing_pct_sao2\", ascending=False)\n",
    ")\n",
    "print(\"\\n=== SaO2 Missingness by Race ===\")\n",
    "display(tmp)\n",
    "\n",
    "# Impute baseline_sao2 with baseline_spo2 where SaO2 is missing\n",
    "# (Simple substitution per your guideline)\n",
    "mask_sao2_na = data_irr_dropped_2[\"baseline_sao2\"].isna()\n",
    "n_before = mask_sao2_na.sum()\n",
    "\n",
    "data_irr_dropped_2.loc[mask_sao2_na, \"baseline_sao2\"] = data_irr_dropped_2.loc[mask_sao2_na, \"baseline_spo2\"]\n",
    "\n",
    "n_after = data_irr_dropped_2[\"baseline_sao2\"].isna().sum()\n",
    "print(f\"\\nImputed baseline_sao2 using baseline_spo2 for {n_before - n_after} rows (remaining NaNs: {n_after}).\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_irr_dropped_2 = data_irr_dropped_2.drop(columns=\"baseline_spo2\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df = data_irr_dropped_2 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current number of patient records: 9,693\n"
     ]
    }
   ],
   "source": [
    "print(f\"Current number of patient records: {len(final_df):,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "from ydata_profiling import ProfileReport\n",
    "\n",
    "profile = ProfileReport(final_df, title = \"Report\") \n",
    "profile.to_notebook_iframe()\n",
    "\n",
    "# Save the report to an HTML file\n",
    "profile.to_file(\"/Users/mac/Desktop/Dubai-Datathon-2025/team4/profile-report.html\")\n",
    "\n",
    "# note: takes around 20 seconds to run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "age                      int64\n",
       "gender                  object\n",
       "race                    object\n",
       "early_transfusion        int64\n",
       "sofa_score               int64\n",
       "sepsis                   int64\n",
       "admission_type          object\n",
       "heart_disease            int64\n",
       "kidney_disease           int64\n",
       "history_of_bleeding      int64\n",
       "baseline_hemoglobin    float64\n",
       "baseline_wbc           float64\n",
       "on_vasopressors          int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 215,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "predictors = [\"age\",\"gender\",\"race\",\"early_transfusion\",\"sofa_score\",\"sepsis\",\n",
    "                \"admission_type\",\"heart_disease\",\"kidney_disease\",\"history_of_bleeding\",\n",
    "                \"baseline_hemoglobin\",\"baseline_wbc\",\"on_vasopressors\"]\n",
    "\n",
    "final_df[predictors].dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop_first=True avoids multicollinearity (drops one dummy per feature).\n",
    "final_df = pd.get_dummies(final_df, columns=[\"gender\", \"race\", \"admission_type\"], drop_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       4\n",
       "1       6\n",
       "2       2\n",
       "3       4\n",
       "4       3\n",
       "       ..\n",
       "9688    2\n",
       "9689    8\n",
       "9690    7\n",
       "9691    1\n",
       "9692    1\n",
       "Name: number_of_transfusions, Length: 9693, dtype: int64"
      ]
     },
     "execution_count": 223,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_df[\"number_of_transfusions\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class counts after binning:\n",
      "number_of_transfusions\n",
      "Q1    3709\n",
      "Q3    1972\n",
      "Q2     860\n",
      "Name: count, dtype: int64\n",
      "Train shape: (5232, 87), Test shape: (1309, 87)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mac/anaconda3/envs/dubai-datathon-team4/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1247: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n",
      "/Users/mac/anaconda3/envs/dubai-datathon-team4/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          Q1       0.98      0.91      0.94       742\n",
      "          Q2       0.58      0.88      0.70       172\n",
      "          Q3       0.98      0.88      0.93       395\n",
      "\n",
      "    accuracy                           0.90      1309\n",
      "   macro avg       0.85      0.89      0.86      1309\n",
      "weighted avg       0.93      0.90      0.91      1309\n",
      "\n",
      "Confusion matrix:\n",
      "[[678  63   1]\n",
      " [ 13 152   7]\n",
      " [  2  45 348]]\n",
      "\n",
      "Bin ranges (on original number_of_transfusions):\n",
      "                        min   max  count\n",
      "number_of_transfusions                  \n",
      "Q1                      1.0   2.0   3709\n",
      "Q2                      3.0   3.0    860\n",
      "Q3                      4.0  76.0   1972\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/sw/5f53r1m13rq2jww8lqgbks700000gn/T/ipykernel_17197/2424041185.py:106: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  [y_raw.groupby(y_binned).min().rename(\"min\"),\n",
      "/var/folders/sw/5f53r1m13rq2jww8lqgbks700000gn/T/ipykernel_17197/2424041185.py:107: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  y_raw.groupby(y_binned).max().rename(\"max\"),\n"
     ]
    }
   ],
   "source": [
    "# -----------------------------------------------\n",
    "# 1) Imports\n",
    "# -----------------------------------------------\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "# -----------------------------------------------\n",
    "# 2) Setup: target & features\n",
    "# -----------------------------------------------\n",
    "TARGET = \"number_of_transfusions\"\n",
    "df = final_df.copy()\n",
    "\n",
    "# Drop rows with any NaNs (either in features or target)\n",
    "df = df.dropna().copy()\n",
    "\n",
    "# Drop rows where target missing or non-numeric\n",
    "df = df[pd.notnull(df[TARGET])].copy()\n",
    "\n",
    "# Ensure target numeric and non-negative\n",
    "y_raw = df[TARGET].astype(float)\n",
    "y_raw = np.clip(y_raw, a_min=0, a_max=None)\n",
    "\n",
    "# -----------------------------------------------\n",
    "# 3) Create bins for classification\n",
    "# -----------------------------------------------\n",
    "def make_quantile_bins(y, q):\n",
    "    labels = [f\"Q{i}\" for i in range(1, q + 1)]\n",
    "    y_b = pd.qcut(y, q=q, labels=labels, duplicates=\"drop\")\n",
    "    return y_b.astype(\"category\")\n",
    "\n",
    "y_binned = None\n",
    "for q in (4, 3, 2):\n",
    "    try:\n",
    "        y_try = make_quantile_bins(y_raw, q)\n",
    "        if y_try.value_counts().min() >= 2:\n",
    "            y_binned = y_try\n",
    "            break\n",
    "    except Exception:\n",
    "        pass\n",
    "\n",
    "# Fallback: binary 0 vs >0\n",
    "if y_binned is None:\n",
    "    y_binned = pd.Series(np.where(y_raw == 0, \"0\", \">0\"), index=df.index).astype(\"category\")\n",
    "\n",
    "print(\"Class counts after binning:\")\n",
    "print(y_binned.value_counts())\n",
    "\n",
    "# -----------------------------------------------\n",
    "# 4) Define X (all variables except target)\n",
    "# -----------------------------------------------\n",
    "X = df.drop(columns=[TARGET])\n",
    "\n",
    "# Identify categorical vs numeric automatically\n",
    "cat_cols = X.select_dtypes(include=[\"object\", \"category\", \"bool\"]).columns.tolist()\n",
    "num_cols = X.select_dtypes(include=[np.number]).columns.tolist()\n",
    "\n",
    "# -----------------------------------------------\n",
    "# 5) Split safely\n",
    "# -----------------------------------------------\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y_binned, test_size=0.2, random_state=42, stratify=y_binned\n",
    ")\n",
    "\n",
    "print(f\"Train shape: {X_train.shape}, Test shape: {X_test.shape}\")\n",
    "\n",
    "# -----------------------------------------------\n",
    "# 6) Build preprocessing + model pipeline\n",
    "# -----------------------------------------------\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"cat\", OneHotEncoder(handle_unknown=\"ignore\", sparse_output=False), cat_cols),\n",
    "        (\"num\", \"passthrough\", num_cols),\n",
    "    ],\n",
    "    remainder=\"drop\",\n",
    ")\n",
    "\n",
    "clf = Pipeline(\n",
    "    steps=[\n",
    "        (\"prep\", preprocessor),\n",
    "        (\"logreg\", LogisticRegression(max_iter=1000, class_weight=\"balanced\", multi_class=\"auto\"))\n",
    "    ]\n",
    ")\n",
    "\n",
    "# -----------------------------------------------\n",
    "# 7) Train & evaluate\n",
    "# -----------------------------------------------\n",
    "clf.fit(X_train, y_train)\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "print(\"\\nClassification report:\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "print(\"Confusion matrix:\")\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "\n",
    "# Optional: show bin ranges\n",
    "if set(y_binned.unique()) - {\"0\", \">0\"}:\n",
    "    desc = pd.concat(\n",
    "        [y_raw.groupby(y_binned).min().rename(\"min\"),\n",
    "         y_raw.groupby(y_binned).max().rename(\"max\"),\n",
    "         y_binned.value_counts().rename(\"count\")],\n",
    "        axis=1\n",
    "    ).sort_index()\n",
    "    print(\"\\nBin ranges (on original number_of_transfusions):\")\n",
    "    print(desc)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dubai-datathon-team4",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.25"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
